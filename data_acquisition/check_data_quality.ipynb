{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another analysis I found that some of the user-ids are no Integers, this seems to be a data quality issue. In this notebook we try to get some statistics on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import commands as cmd\n",
    "\n",
    "root_path = cmd.getoutput('pwd')[:cmd.getoutput('pwd').find('/databeers/')] + '/databeers'\n",
    "data_path = root_path + \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from src.read_write_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_paths = [x[x.rfind('users_'):] for x in cmd.getoutput('ls %s/users_*'%data_path).split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_integer(df, colname):\n",
    "    \"\"\"\n",
    "    check in column of pandas dataframe how many entries are integers, non-integers and NA-values.\n",
    "    \"\"\"\n",
    "    vc = df[colname].str.match(\"[0-9]+\").value_counts()\n",
    "    return vc.get(True, 0), vc.get(False, 0), len(df[colname]) - df[colname].count()\n",
    "\n",
    "\n",
    "def check_id_cols(path):\n",
    "    \"\"\"\n",
    "    check in a path if the id-column is correct. \n",
    "    Returns pd.DataFrame with statistics about correct, incorrect and NA-ids.\n",
    "    \"\"\"\n",
    "    df_tmp = load_df(data_path + path)[[\"id\", \"id_str\"]]\n",
    "        \n",
    "    id_corr, id_incorr, id_na = check_integer(df_tmp, \"id\")\n",
    "    id_str_corr, id_str_incorr, id_str_na = check_integer(df_tmp, \"id_str\")\n",
    "    \n",
    "    return pd.DataFrame([[path, id_corr, id_incorr, id_na, id_str_corr, id_str_incorr, id_str_na]],\n",
    "                         columns=['path', 'id_corr', 'id_incorr', 'id_na',\n",
    "                                  'id_str_corr', 'id_str_incorr', 'id_str_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id_corr</th>\n",
       "      <th>id_incorr</th>\n",
       "      <th>id_na</th>\n",
       "      <th>id_str_corr</th>\n",
       "      <th>id_str_incorr</th>\n",
       "      <th>id_str_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>users_10060800.csv</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path  id_corr  id_incorr  id_na  id_str_corr  id_str_incorr  \\\n",
       "0  users_10060800.csv       53          0      0           53              0   \n",
       "\n",
       "   id_str_na  \n",
       "0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_id_cols('users_10060800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_sample = np.random.choice(user_paths, size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress 50\n",
      "progress 100\n",
      "progress 150\n",
      "progress 200\n",
      "progress 250\n",
      "progress 300\n",
      "progress 350\n",
      "progress 400\n",
      "progress 450\n",
      "progress 500\n",
      "progress 550\n",
      "progress 600\n",
      "progress 650\n",
      "progress 700\n",
      "progress 750\n",
      "progress 800\n",
      "progress 850\n",
      "progress 900\n",
      "progress 950\n"
     ]
    }
   ],
   "source": [
    "for idx, path in enumerate(path_sample.tolist()):\n",
    "    if idx == 0:\n",
    "        stats_df = check_id_cols(path)\n",
    "    else:\n",
    "        if idx%50 == 0:\n",
    "            print 'progress', idx\n",
    "        stats_df = stats_df.append(check_id_cols(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_df[\"perc_incorr_id\"] = stats_df[\"id_incorr\"] / (stats_df[\"id_incorr\"] + stats_df[\"id_corr\"])\n",
    "stats_df[\"perc_incorr_str_id\"] = stats_df[\"id_str_incorr\"] / (stats_df[\"id_str_incorr\"] + stats_df[\"id_str_corr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum incorrect id string 0.00597907324365\n",
      "maximum incorrect id int 0.00548081714001\n"
     ]
    }
   ],
   "source": [
    "print 'maximum incorrect id string', max(stats_df[\"perc_incorr_str_id\"])\n",
    "print 'maximum incorrect id int', max(stats_df[\"perc_incorr_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id == str_id in corr False\n",
      "id == str_id in incorr False\n",
      "id == str_id in na True\n"
     ]
    }
   ],
   "source": [
    "for col in [\"id_{}corr\", \"id_{}incorr\" ,\"id_{}na\"]:\n",
    "    print 'id == str_id in', col[col.rfind('}')+1:], all(stats_df[col.format(\"\")] == stats_df[col.format(\"str_\")].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_paths = [x[x.rfind('clean_users_'):] for x in cmd.getoutput('ls %s/daily_users/clean_users_*'%data_path).split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress 10\n",
      "progress 20\n",
      "progress 30\n",
      "progress 40\n",
      "progress 50\n",
      "progress 60\n"
     ]
    }
   ],
   "source": [
    "for idx, path in enumerate(clean_paths):\n",
    "    path = \"daily_users/\" + path\n",
    "    if idx == 0:\n",
    "        stats_clean_df = check_id_cols(path)\n",
    "    else:\n",
    "        if idx%10 == 0:\n",
    "            print 'progress', idx\n",
    "        stats_clean_df = stats_clean_df.append(check_id_cols(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_clean_df[\"perc_incorr_id\"] = stats_clean_df[\"id_incorr\"] / (stats_clean_df[\"id_incorr\"] + stats_clean_df[\"id_corr\"])\n",
    "stats_clean_df[\"perc_incorr_str_id\"] = stats_clean_df[\"id_str_incorr\"] / (stats_clean_df[\"id_str_incorr\"] + stats_clean_df[\"id_str_corr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum incorrect id string in daily users 3.8731466993e-05\n",
      "maximum incorrect id in daily users 0.0\n"
     ]
    }
   ],
   "source": [
    "print 'maximum incorrect id string in daily users', max(stats_clean_df[\"perc_incorr_str_id\"])\n",
    "print 'maximum incorrect id in daily users', max(stats_clean_df[\"perc_incorr_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast part of the user df seems to be ok, lets check the tweets as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_paths = [x[x.rfind('tweets_'):] for x in cmd.getoutput('ls %s/tweets_*'%data_path).split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_id_cols_tweets(path):\n",
    "    df_tmp = load_df(data_path + path)[[\"user_id\"]]\n",
    "    \n",
    "    id_corr, id_incorr, id_na = check_integer(df_tmp, \"user_id\")\n",
    "    return pd.DataFrame([[path, id_corr, id_incorr, id_na]],\n",
    "                         columns=['path', 'id_corr', 'id_incorr', 'id_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "for idx, path in enumerate(tweet_paths):\n",
    "    if idx == 0:\n",
    "        stats_tweets_df = check_id_cols_tweets(path)\n",
    "    else:\n",
    "        if idx%50 == 0:\n",
    "            print idx\n",
    "        stats_tweets_df = stats_tweets_df.append(check_id_cols_tweets(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum percentage incorrect ids 31.0 [%]\n"
     ]
    }
   ],
   "source": [
    "stats_tweets_df[\"perc_incorr_id\"] = stats_tweets_df[\"id_incorr\"] / (stats_tweets_df[\"id_incorr\"] + stats_tweets_df[\"id_corr\"])\n",
    "print 'maximum percentage incorrect ids', round(max(stats_tweets_df[\"perc_incorr_id\"])*100), '[%]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id_corr</th>\n",
       "      <th>id_incorr</th>\n",
       "      <th>id_na</th>\n",
       "      <th>perc_incorr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07081600.csv</td>\n",
       "      <td>6689</td>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07081700.csv</td>\n",
       "      <td>8213</td>\n",
       "      <td>579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07081800.csv</td>\n",
       "      <td>8926</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07081900.csv</td>\n",
       "      <td>9163</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07082000.csv</td>\n",
       "      <td>8966</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07082100.csv</td>\n",
       "      <td>9105</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07082200.csv</td>\n",
       "      <td>8573</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_07082300.csv</td>\n",
       "      <td>8506</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080000.csv</td>\n",
       "      <td>8027</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080100.csv</td>\n",
       "      <td>7604</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080200.csv</td>\n",
       "      <td>8115</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080300.csv</td>\n",
       "      <td>7138</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080400.csv</td>\n",
       "      <td>5777</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080500.csv</td>\n",
       "      <td>4595</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08080600.csv</td>\n",
       "      <td>3566</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08081400.csv</td>\n",
       "      <td>4787</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08081700.csv</td>\n",
       "      <td>6084</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_08082100.csv</td>\n",
       "      <td>7675</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080000.csv</td>\n",
       "      <td>8362</td>\n",
       "      <td>3837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080100.csv</td>\n",
       "      <td>11356</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080200.csv</td>\n",
       "      <td>11006</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080300.csv</td>\n",
       "      <td>8382</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080400.csv</td>\n",
       "      <td>6457</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15080900.csv</td>\n",
       "      <td>2696</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15081200.csv</td>\n",
       "      <td>3629</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_15081300.csv</td>\n",
       "      <td>4043</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_20082300.csv</td>\n",
       "      <td>11662</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070000.csv</td>\n",
       "      <td>8900</td>\n",
       "      <td>1117</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070100.csv</td>\n",
       "      <td>8301</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070200.csv</td>\n",
       "      <td>7669</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070300.csv</td>\n",
       "      <td>8385</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070400.csv</td>\n",
       "      <td>6311</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070500.csv</td>\n",
       "      <td>4926</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25070600.csv</td>\n",
       "      <td>3717</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071000.csv</td>\n",
       "      <td>2332</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071100.csv</td>\n",
       "      <td>2949</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071400.csv</td>\n",
       "      <td>5083</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071500.csv</td>\n",
       "      <td>6291</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071600.csv</td>\n",
       "      <td>7426</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25071800.csv</td>\n",
       "      <td>7555</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_25072300.csv</td>\n",
       "      <td>7685</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_27070800.csv</td>\n",
       "      <td>3055</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweets_30072100.csv</td>\n",
       "      <td>11229</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  path  id_corr  id_incorr  id_na  perc_incorr_id\n",
       "0  tweets_07081600.csv     6689       1672      0        0.199976\n",
       "0  tweets_07081700.csv     8213        579      0        0.065855\n",
       "0  tweets_07081800.csv     8926        429      0        0.045858\n",
       "0  tweets_07081900.csv     9163        186      0        0.019895\n",
       "0  tweets_07082000.csv     8966        175      0        0.019145\n",
       "0  tweets_07082100.csv     9105         95      0        0.010326\n",
       "0  tweets_07082200.csv     8573       3300      0        0.277942\n",
       "0  tweets_07082300.csv     8506        820      0        0.087926\n",
       "0  tweets_08080000.csv     8027        362      0        0.043152\n",
       "0  tweets_08080100.csv     7604        214      0        0.027373\n",
       "0  tweets_08080200.csv     8115        214      0        0.025693\n",
       "0  tweets_08080300.csv     7138         98      0        0.013543\n",
       "0  tweets_08080400.csv     5777        263      0        0.043543\n",
       "0  tweets_08080500.csv     4595         60      0        0.012889\n",
       "0  tweets_08080600.csv     3566         54      0        0.014917\n",
       "0  tweets_08081400.csv     4787         79      0        0.016235\n",
       "0  tweets_08081700.csv     6084         74      0        0.012017\n",
       "0  tweets_08082100.csv     7675         85      0        0.010954\n",
       "0  tweets_15080000.csv     8362       3837      0        0.314534\n",
       "0  tweets_15080100.csv    11356       1328      0        0.104699\n",
       "0  tweets_15080200.csv    11006        757      0        0.064354\n",
       "0  tweets_15080300.csv     8382        351      0        0.040192\n",
       "0  tweets_15080400.csv     6457        185      0        0.027853\n",
       "0  tweets_15080900.csv     2696         58      0        0.021060\n",
       "0  tweets_15081200.csv     3629         91      0        0.024462\n",
       "0  tweets_15081300.csv     4043         91      0        0.022013\n",
       "0  tweets_20082300.csv    11662        251      0        0.021069\n",
       "0  tweets_25070000.csv     8900       1117      0        0.111510\n",
       "0  tweets_25070100.csv     8301        862      0        0.094074\n",
       "0  tweets_25070200.csv     7669        362      0        0.045075\n",
       "0  tweets_25070300.csv     8385        195      0        0.022727\n",
       "0  tweets_25070400.csv     6311        138      0        0.021399\n",
       "0  tweets_25070500.csv     4926         79      0        0.015784\n",
       "0  tweets_25070600.csv     3717         39      0        0.010383\n",
       "0  tweets_25071000.csv     2332         30      0        0.012701\n",
       "0  tweets_25071100.csv     2949         30      0        0.010070\n",
       "0  tweets_25071400.csv     5083         76      0        0.014732\n",
       "0  tweets_25071500.csv     6291         81      0        0.012712\n",
       "0  tweets_25071600.csv     7426         81      0        0.010790\n",
       "0  tweets_25071800.csv     7555        142      0        0.018449\n",
       "0  tweets_25072300.csv     7685         81      0        0.010430\n",
       "0  tweets_27070800.csv     3055         39      0        0.012605\n",
       "0  tweets_30072100.csv    11229        148      0        0.013009"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hours with more than 1% incorrect\n",
    "print len(stats_tweets_df[stats_tweets_df[\"perc_incorr_id\"] > 0.01])\n",
    "stats_tweets_df[stats_tweets_df[\"perc_incorr_id\"] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min date 609\n",
      "max date 829\n"
     ]
    }
   ],
   "source": [
    "print 'min date', min([int(x[7:9]) + 100 * int(x[9:11]) for x in tweet_paths])\n",
    "print 'max date', max([int(x[7:9]) + 100 * int(x[9:11]) for x in tweet_paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet data also seems kind of alright, however there is a problem for some dates 27.07, 07.08, 08.08, 15.08"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}